# 如何在ComfyUI从零开始搭建一套商业工作流？

> 来源：[https://ktnwm6ohjn.feishu.cn/docx/IHdDdCkpdoCbJQxF7vRcoM0snJf](https://ktnwm6ohjn.feishu.cn/docx/IHdDdCkpdoCbJQxF7vRcoM0snJf)

## 1 前言

大家好，我是土豆君，喜欢折腾各种技术的程序员。

之前我写过一篇零基础线上ComfyUI跑图的教程，只要有工作流就能跑起来： 。（没学习过可以了解下，今天的帖子是进阶内容。）

那么，当我们想要进一步使用ComfyUI去做商业化的时候，肯定还需要对已有工作流按需要进行修改。但如果我们不了解每个节点的机制又如何修改工作流呢？哪怕一些模块可以复用，自己也不知道该如何连线。

如果我们能够拆解一套商业化工作流又或是能从零搭建一套商业化工作流就好办了。而这就是这篇帖子要解决的问题，学会拆解别人的工作流就能一通百通。

其实一套工作路核心节点都是相似的，无非细节大同小异。我们只要抓住核心，就能轻松的理解这套工作流的原理。

接下来，我主要以电商场景来展开，针对两个商业化场景：电商换背景、电商换装来说明如何拆解一套商业化工作流并从零搭建出来。

## 2 拆解主流电商换背景工作流

### 2.1 电商案例拆解

首先，我们打开 LiblibAI，Liblib平台工作流非常多，我们从其中搜索一套商业化电商换背景工作流并不复杂。

![](img/815ac733653cc3bd1201b6c68f68c115.png)

LibLib搜索换背景，我们就以这个运行数最多的工作流来作为拆解案例展示。

打开Liblib工作流 电商产品换背景。

先运行看下效果：给产品换上合适的AI背景效果图，并且保留文字效果。

![](img/69946cb065c7c343b9c1f7225a76839d.png)

![](img/4b23a6095d37990e6b86b6bd8550183e.png)

接下来看下工作流详情。密密麻麻一大堆，看着就头疼。

![](img/c3c93cc5fdd0463b9a48f252026d2143.png)

我们先观测工作流各个模块，进行划分。这套工作流有三个部分：首次出图、FLUX二次细化重绘、最终打光并高清放大。

首次出图模块明显就是核心部分，产品换背景在这部分完成的。

![](img/7f9cacafcbebb0ccd8a69f5a537af6d2.png)

FLUX二次细化重绘模块实际上就是在首次出图的基础上图生图。

![](img/6776468b15ceb217ed553991ceccbc10.png)

最终打光并高清放大模块就是一个高清放大基础工作流，然后叠加一个打光模块组件。

![](img/77f29e74d5580c48cd116e8343d4e8cb.png)

分析下来，我们抓关键的首次出图工作流就行。而FLUX重绘、高清放大都是属于基础工作流，也是可以复用的组件。

### 2.2 搭建思路拆解

接下来我们就看工作流中的首次出图模块做了哪些事情。并把产品换背景工作流中首次出图模块的相关的组件都找出来。

1.  图像预处理，主要是抠图，比如使用 SegmentAnything。图像输入可以控制一下图片宽高。

1.  风格化和局部重绘。保留产品抠图，只需要对背景重绘，并且要确保绘制的背景和产品能融合到一起。

1.  控制背景图像生成的稳定性。 为了减少提示词的不稳定性，我们还可以加入 ControlNet 控制图像的一些属性。

1.  文字处理。产品一般会带有文字，AI生成的图片文字基本是乱码，因此需要对产品图和生成的AI图片进行融合。

然后我们就把用到的模块都找出来，尝试如何从零开始搭建出一个产品换背景的工作流。

其实搭建一个工作流没那么复杂，因为任何一个工作流都是从文生图或图生图的基础工作流演进的。而思路无非就是在原来基础的工作流上添加需要的组件，然后把组件串联到这个基础流程中。

![](img/609addefe729f6ad86d06fb952b50475.png)

按照这个思路，我们把各个部分组件拆解出来。

### 2.3 组件拆解

我们刚才已经把首次出图模块做了哪些事情梳理出来了，接下来就一一梳理这些用到的组件：

#### 图像处理

图像处理需要用到这4个组件：宽高比缩放、SegmentAnything、遮罩模糊生长、混合。

*   宽高比缩放主要用于对图像进行缩放操作，这里用来固定输入图像的大小，方便图像处理。

*   Segment Anything 是一个图像分割模型，可以自动识别图像中的不同对象。这里用来分隔图片的物体，并生成蒙蔽。

*   遮罩模糊生长 对遮罩（mask）进行处理。模糊操作可以使遮罩的边缘变得更加平滑，减少硬边缘的出现；生长操作则可以扩大遮罩的范围，使遮罩覆盖更多的区域。

*   混合：将多个图像、遮罩或其他数据按照一定的比例进行混合。这里用于文字处理，AI生成的图像文字有问题，需要把原来的产品图混合，让文字显示清晰。

![](img/e07daf87c07143e880ce0a62a053ff56.png)

#### 风格化

IPAdapter 用来生成风格化图像，可以提供一张或多张参考图像，从而使生成的图像在风格、内容细节等方面与参考图像更为相似。

![](img/abe84c357371a2782e95af60bd3f684a.png)

#### 局部重绘

BrushNet 主要用于图像编辑和生成过程中的局部控制，也就是用于局部重绘。在这里用于给分割后的图像蒙版重绘背景，所以选择 segmentation_mask 模型。

![](img/8a4ea5e0c17ad58f296ac32336f3921e.png)

#### ControlNet 控制

Aux集成预处理器将图像转为线性图和深度图，然后使用对应的线性、深度模型用ControNet进行精确控制。

![](img/e5d583597eaa9bf75f9788b895c94075.png)

#### 提示词和Lora

提示词和Lora这部分就简单了，添加自己想要的模型和Lora增强效果。而提示词可以加入翻译组件方便使用中文写提示词。

![](img/7d4fbd682ae843e8ca008376ce825517.png)

### 2.4 搭建模块

工作流搭建我们可以先把各个组件模块串联好，然后把组件串联到基础的图生图工作流。

#### 图像处理模块

先对图片进行缩放，然后抠图，处理下蒙版，最后加载背景图混合。

![](img/de7dde40eedf69fe3ada024faf526909.png)

这里我们把需要AI生成的背景图像用加载的形式简化，后面搭建完整的工作流只需要去掉加载图像部分就行了。

参数基本使用默认的就行，可以根据出图效果一步步调整。

#### 重绘模块

先连接IPAdapter，然后串联BrushNet。

![](img/be8e2c3ccbe226e601a3c30c8eecaf80.png)

这里的参数调整下开始和结束应用的位置。

![](img/dc6304aec3b2c72e1897c97ed4723638.png)

像这种空心的圆圈，表示可以不连接，非必须输入结点。

![](img/f182348bb6b35908a2abb47178a69bd6.png)

#### ControlNet 模块

把Aux和CN加载器连接到CN应用，再串联一个CN应用。

![](img/f34fa17d8cf2a9857601c2cb45e353c0.png)

#### 提示词和Lora模块

注意案例中的大模型和Lora为示例，不一定非要用一样的模型，可以自行选择通用模型

一站式电商大模型-场景-产品-主图-Checkpoint-Colorshow_绘梦星创-LiblibAI

J_电商场景_森林_实验室_场景-LoRA-J_-LiblibAI

QLCD-电商森林雪山水景背景XL_建模渲染自然实景-LoRA-QLCD设计工作室-LiblibAI

SDXL护肤品，化妆品产品摄影/场景图/电商-LoRA-植栋-LiblibAI

![](img/f6a63a528d53b2bc01df3294d113d69e.png)

然后我们把这些部分串联起来，结合图生图基础工作流，缺什么补什么。

### 2.5 搭建工作流

我们从头开始把各个模块连接起来。为了方便连线，不至于连线太混乱，这里我引入了一组设置节点、获取节点，功能就是代码中的设置变量的意思，可以把节点存为一个变量，这样就不需要连那么长的线。

![](img/4274ab4e7252a3f4496c4c1f9889b5c1.png)

![](img/82708072fd5f06eb60c726ec12b24779.png)

![](img/629a3615c14aed7b41c6d6cc0b44d5c7.png)

#### 输入部分

开头部分设置一个VAE，后面需要使用。

![](img/5700a9368b5fb182e824f6c0a0811fe9.png)

图像处理模块分别设置图像节点、抠图图像、抠图蒙版节点。

![](img/a28ecada343eab5b82b95be80d029d69.png)

#### 绘图部分

然后把提示词模块的模型节点和正负条件连接到重绘模块。

使用获取节点，把设置的VAE节点连接上。

![](img/ab6ff1369f28f3fca2a7ac6d0f0ce90e.png)

然后连接原图、抠图图像和抠图蒙版。这里需要注意，IPAdapter连接的图像不是抠图后的图像，而是宽高比缩放后载入的原图。

![](img/f0aa6ec7359ef0a1bf5207b948ee693f.png)

而BrushNet连接的图像是抠图图像和抠图蒙版。

![](img/323479520d452d7c9b9c6169bbc19a89.png)

把BrushNet的正负条件连接到ControNet的正负条件上，传递下去，一致传递到K采样器。

把VAE和抠图图像连接到Aux处理器。

![](img/84cefc44eb5a86cc47c011f194aaf164.png)

#### 输出部分

最后就是连接采样器。

前面ControNet正负条件、BrushNet模型和Latent连接到K采样器

![](img/dcd18fef59630b71a4f80c59352f982e.png)

这样我们运行一下，能生成图像，说明连接没有问题。

![](img/c7511ca64600b3c8bd014390afda9daa.png)

#### 文字处理

这里把生成的图像放大，发现文字都是乱码，怎么回事呢？其实这就是因为AI生成的图像不能自动处理好文字。

![](img/31a5eaea4261960e25f25255a0f0be33.png)

还记得前面我们提到混合组件么？混合组件的背景图像和输出图像我们还没连线呢。

混合组件在这个工作流可以帮我们处理文字效果。

![](img/927902f1a301ef06c56e73ec191cfb53.png)

因此我们再把AI生成好的VAE解码后的图像连接过来，保存效果图，这才是最终的输出。

![](img/9b08eb829bf02f0362f797bfb886bb46.png)

生成的效果图如下，这个文字才是正常的。

![](img/7c9bad36bd1c2afc0455591921c6bcf8.png)

#### 高清放大

生成了满意的效果图后，你可以还需要把图片放大，这时候需要接入一个放大工作流。

我比较建议高清放大单独处理，因为高清放大只有在你输出的图片满意的情况才需要放大，而且运行起来很耗时，因此我更推荐单独用一个工作流来处理放大过程。

至于放大的方式本身也很多，可以自由选择，我们这里使用 Flux + SDUpscale 的方式放大。

![](img/6a0467b7448a8b90497fbf8737815de1.png)

![](img/4298b7f6558f36ad338c4440f8296c9b.png)

最后说下工作流里面只能运行一套工作流，两套同时使用会爆显存。这里我把高清放大的工作流给屏蔽了，平时这样使用就行了。

![](img/4e449a5449d76d568c63ea3f9abed25d.png)

右键工作流框，选择忽略框内节点，即可屏蔽整个框的工作流。

![](img/72738d4fd9f273daac11cff5b4650222.png)

右键工作流框，选择启用框内节点，即可把屏蔽的工作流启用。

![](img/fe74b07327359959e5ae9edb8f311f95.png)

放上这个搭建的案例的工作流供大家参考：

电商换背景.json

另外，补充电商场景常用的抠图的工作流供大家学习，工作流展示了几种抠图的模型，没有最好的抠图，只有最适合场景的抠图模型。

一键抠图.json

## 3 从零搭建 Fill-Redux 万物迁移工作流

上面电商换背景案例是从拆解的方式开始，接下来我们就换个方式，从零开始搭建 Fill-Redux工作流，正好学习一下Flux模型重绘的用法。

在 Liblib 上搜索 Redux 就能看到很多 Fill Redux 的换装、迁移工作流，其实核心工作流都一样没那么多区别。接下来我就带你从最基础的文生图工作流搭建出商业化的 Fill-Redux 工作流。

![](img/b8dd6ff0005cc0f55e9ec7e0f503fc3c.png)

先了解下概念。

### 3.1 Fill 和 Redex 是什么

Flux 模型在文生图的效果非常出色，但在图生图，特别是局部重绘效果就很差，因此官方就发布了 FLUX.1 Tools 包，而其中 FLUX.1 Fill 模型专门用来重绘，FLUX.1 Redux 模型用来风格迁移。

这里引用官方介绍来说明。

FLUX.1 Fill:

![](img/798388163cb9215dc4fe1f1c8031bc1a.png)

FLUX.1 Redux:

![](img/39688f3e2623b69d84605c2af38e2384.png)

详细介绍可以查看官网：https://blackforestlabs.ai/flux-1-tools

简单的理解，Redex 模型可以用 Fill 模型对图生图做局部重绘。在电商工作流里面我们用 IPAdapter 引导生成风格，而在 Flux 模型中可以使用 Redux 引导风格，搭配 Fill 模型做重绘。而且重绘迁移的效果非常好，基本上商用场景都可以满足。

### 3.2 工作流使用

先来介绍如何使用。打开工作流，先在参考图片区域上传上传单色背景的产品图，比如服装图。当然，除了服装，其他的任何物品都可以迁移。

![](img/00a4e3a25375c026f94a516ccc469388.png)

![](img/6151e7b65005266b1abe2ab3aa0c1328.png)

然后，在模特图片区域，上传要重绘的模特图片。 上传模特图后，右键点击图片，在遮罩编辑器中打开，涂抹需要重绘的部分，注意要完全覆盖，多一点也没事， 涂抹完遮罩后点击生成即可。

![](img/89b41691a47a7254c668286677d0e69a.png)

![](img/9526354e1f3e037cad68b90a8e63a995.png)

涂抹模特服装部分：

![](img/9a724e4c4ead8d454611efbc2409669a.png)

![](img/b0d60f88a93bb52c61b0c16f2eb1a104.png)

生成图的效果对比：

![](img/5cc06e71544cac94affa61f84a66b9ea.png)

![](img/ea145ef0b256fa946a0f0c36b668680b.png)

然后我们就尝试开始搭建。

### 3.3 工作流搭建

#### 3.3.1 Flux 文生图

我们还是从这个默认的SD文生图工作流开始搭建。

![](img/0acd38e469f03d4a0fb51f9730646d00.png)

先改造为 Flux 文生图工作流，去掉 Checkpoint加载器，使用 UNET加载器、双CLIP加载器。

Flux-fp8模型：F.1基础算法模型-哩布在线可运行-Checkpoint-热点推荐官-LiblibAI

![](img/8e1dcb40fdb8d9160eb82685576ff4f5.png)

然后我们在正面条件前加入一个 Flux 引导，表示使用使用Flux引导，所以把K采样器的CFG参数调整为1。

文生图，Flux引导值推荐默认值，官方推荐3.5。采样步数默认20，可酌情提高。

![](img/396cd14ff5f4d58dde37c8132dd55bb5.png)

这样一个文生图的Flux工作流就搭建好了。当然，Flux其实是没有负面条件的，我们可以新增一个条件零化连接到负面条件，删除多余的负面条件的CLIP文本编码器。（条件零化作用：删除提示词文本条件）

![](img/e652aeb04c48947551d8f09c3b16e134.png)

#### 3.3.2 Flux 图生图

接下来我们把Flux文生图工作流改造为Flux图生图工作流。删除空Latent，使用VAE编码加载图像，引入VAE加载器、加载图像节点。

![](img/43de47f453f2f0d755e349bc27f6c561.png)

#### 3.3.3 Flux 局部重绘

我们添加一个设置Latent噪波遮罩节点，连接蒙版，这就是一个图像局部微调的工作流。

![](img/a681c78f730271f981c929b7065583fc.png)

#### 3.3.4 Fill 局部重绘

接下来我们把Flux重绘工作流改为 Flux Fill 模型的重绘工作流。

注意：

*   在用 Fill模型重绘的时候，官方不推荐使用通常的Latent噪波遮罩节点，这样的重绘效果比较差，需要使用内补模型条件节点。

*   Fill官方原版模型23.8G，如果本地显卡没有24G显存，建议在线上使用。

*   Fill模型引导值要使用30，官方推荐。

![](img/d163ce8bc61a091b89be2aa0632ec7af.png)

内补模型条件串联到条件节点（Flux引导）和K采样器节点之间。然后把模型切换为 F.1-Fill-fp16_Inpaint&Outpaint 模型，Flux引导值改为30。

Fill-fp16模型：F.1-Fill-fp16_Inpaint& Outpaint-Checkpoint-热点推荐官-LiblibAI

![](img/5d466ed65d210e8640a36f713ee04a51.png)

我们来测试一下，比如，在提示词写上Wear a cute cat hat (戴一顶可爱的猫帽子)。加载一张女生图像，右键选择在遮罩编辑器中打开，涂抹头顶的部分。然后点击生成。

![](img/c651aba698a018825a82333161bc30bf.png)

嗯，效果还不错。

![](img/c2e2a192ede57f46b0a3f01627d43c14.png)

![](img/ee13de2bb19a9ef7996817aa4a973dd1.png)

然后我们整理下工作流，按住Ctrl选中全部节点，然后按 Ctrl+G，就能自动新建框打组。

![](img/61b0f70cb3c0cd44e4d0d1b89b2747d3.png)

#### 3.3.5 Fill + Redux 风格迁移

找到ReduxAdvanced节点，把它串联到条件节点（Flux引导）和内补模型条件节点之间。

![](img/7dc14503214228bf6d21a33779aebb92.png)

然后在输入端添加风格模型加载器、CLIP视觉加载器、加载图像节点。并调整如下参数。downsampling_factor 表示向下采样，1为最大的参考强度。mode 使用 keep aspect ratio 表示参考整张图像。模型选择 sigclip_vision_patch14_384、flux-redux-dev。

![](img/bc20da001f7f9ce448bae0439681e3db.png)

这里有个小技巧：

其实不需要主动去搜索风格模型、CLIP视觉加载器、加载图像节点，直接从ReduxAdvanced节点的输入端按住鼠标拖一根线出来，松手选择相应的节点就行，这样自然就会有连线。

![](img/9f8f7f4b66786203f404ed3849c39b08.png)

这样我们就搭建好了。

![](img/e961fbf006d087329746696b8f4cd5a6.png)

然后我们还需要接入一个按宽高比缩放_V2节点。因为我们一般上传的图片分辨率都很随意，所以需要做一下处理，自动统一缩放为模型能够接受的图像大小。注意需要把倍数取整改为None，缩放到边改为长边longest。

![](img/a9f04de9b13d02b08b3d5dc7be173513.png)

把按宽高比缩放_V2串联进来，上面和下面两个加载图像的地方都要加进来。

![](img/c690ae40aafa5a10e03c7bbcc5c4bb92.png)

接着我们生图测试一下。

![](img/013917caa67c08193c45d5851e42e531.png)

对比看一下，换装成功了，但是只有一点点相似，很大程度上还是不一样。

![](img/53036d7573380bcda2156186b8da23fd.png)

![](img/1ae7b5c4c749662ee1ab941014fb45c0.png)

#### 3.3.6 Fill + Redux 重绘相似度问题

如果我们使用 Fill + Redux 模型换装的效果只有这种程度，显然是不能商用的，那么如何提高迁移的相似度呢？

这里我们看一下工作流使用的部分，我放了一个效果对比图，有没有感到疑惑？为什么生成图是把两张图拼在一起？

![](img/79e3e675cbf559796423303fcd39ebe6.png)

其实是因为，AI生成的一张图片，图片里面的元素会保持高度相似。

所以我们就可以借助这一点，在产品图的右边直接拼接一个模特图，之后重绘右边模特图的部分，这样参考性就会大大增强，得到的重绘效果也会高度相似。

因此，我们需要拼接两幅图，原图和蒙版图，这样蒙版才能对应上原图。而蒙版的拼接我们可以先生成一个黑色图，再拼接上模特的蒙版图。

![](img/5886e60f04e90136c9e92eb2fe0351ef.png)

![](img/ebe5c7ac5add7acc79e43b52fc3fed39.png)

而最后的出图结果我们可以再把模特图片裁剪出来，这样就达到了风格迁移的目的。

#### 3.3.7 Fill + Redux 万物迁移工作流

##### 图像联结

拼接图像需要用到图像联结的节点，生成黑色蒙版用空图像节点。

![](img/d192bf24c81352c12743fa9b4084473c.png)

空图像我们需要把输入的宽和高转为传入的宽高节点。右键空图像，找到转换为输入，依次选择转换宽度为输入，转换高度为输入。

![](img/513031430434bbb26fb1f35bd78443e4.png)

![](img/243c292c14ef5c933bd8dc61a568f147.png)

还有一组节点需要用到：遮罩到图像、图像到遮罩。

![](img/e069346fa18844306122249b23c4873c.png)

![](img/49413250e9b84b948218b44cbec18d31.png)

具体的联结方式看图，使用图像联结节点，我们把模特图拼接到产品图的右边，图像联结连线到内补模型条件。

![](img/1a9d09c5347acccc376a46f300d477a0.png)

遮罩的图像联结方式也类似，只是需要先使用空图像，空图像的宽高由产品图传入，然后再联结到图像联结。另一边把遮罩连接到图像联结，但因为遮罩到图像需要转换，所以需要使用遮罩到图像、图像到遮罩节点。

![](img/8a9f1751f075e05b3fb0be6a5217e821.png)

连线好后我们把工作流整理一下，添加图像预览节点方便查看，图像联结部分就没问题了。

接下来我们加载图片，涂抹蒙版，运行试下，可以看到两个预览图像联结是成功的。

![](img/b9e0e8d92370c136c1b27e922ab2f44f.png)

然后看下生成图片的效果，这次换装融合的很好，很相似，几乎无差别。

![](img/e6767f2a447f98d1592c8d3505e79748.png)

![](img/9a5b638f464474342fe58a0d719ec4c8.png)

##### 图像裁剪

那么接下来，我们需要把生成的图像进行裁剪，因为我们只需要右半部分。

图像裁剪更简单，只需要用到桥接预览图像、图像裁剪这两个节点。需要注意，图像裁剪同样需要把输入的宽和高转为传入的宽高节点。（右键图像裁剪，找到转换为输入，依次选择转换宽度为输入，转换高度为输入。）另外，图像裁剪的位置，需要改为右上top-right。

![](img/2351feb6d0f476a90204459ca25577d4.png)

![](img/b7e309968e21d27817cf610acfcfc34b.png)

接下来再串联到VAE解码节点之后，而图像裁剪节点的宽高从模特图的缩放图像中传入。运行一下，可以看到裁剪效果OK。

![](img/c589d3600b5a01bb1b2ef7c6b0d8d53d.png)

##### 高清放大

最后我们实现一下高清放大功能。使用 Flux 模型放大，而不是延用Fill模型，Fill模型只适合重绘。放大模型加载器可以随意选择，SD放大的输入连线从Fill生图工作流节点连过来就行了。

![](img/323eabb3e2c59016d954a3dd3d25f78d.png)

![](img/49d74fde7382c4b618e20ce60b33eb38.png)

放上这个案例的工作流供大家参考：

Fill+redux万物迁移.json