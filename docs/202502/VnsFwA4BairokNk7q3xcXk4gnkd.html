<h1>5分钟用满血 DeepSeek R1 搭建个人 AI 知识库（含本地部署）</h1>
<blockquote>来源：<a href="https://zzi7a49xoa.feishu.cn/docx/DZ0ydDEkgohZqXx5GgocReSLnLf">https://zzi7a49xoa.feishu.cn/docx/DZ0ydDEkgohZqXx5GgocReSLnLf</a></blockquote>

<p>最近很多朋友都在问：怎么本地部署 DeepSeek 搭建个人知识库。</p>
<p><img src="img/da14f7e0c7c712663bbcb337bc4e47ac.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/B3uEb3MUOoUaLZxx9pkcoxxrnuf/"/></p>

<p>老实说，如果你不是为了研究技术，或者确实需要保护涉密数据，我真不建议去折腾本地部署。</p>

<p>为什么呢？</p>

<p>目前 Ollama 从 1.5B 到 70B 都只是把 R1 的推理能力提炼到 Qwen 和 Llama 的蒸馏版本（学生模型）上。</p>

<p>虽说性能是提升了不少，但跟原汁原味的 R1 模型比起来，还是差太多了。</p>

<p>官方的满血版本可是 671B 的参数量，说实话，对普通人来说想本地部署，这成本确实太高了。</p>

<p>不过我最近发现了一个平台，不仅能用上 R1 本 1，还提供了不少免费额度。</p>

<p>此外，为了让拥有算力的朋友可以本地部署，我也提供了相关教程。</p>

<p>看完全文，你会收获：</p>

<ol><li>满血 DeepSeek R1 模型 API 搭建个人知识库</li></ol>
<ol><li>本地部署 DeepSeek R1 模型 搭建个人知识库</li></ol>

<h2>一、个人知识库使用效果（满血版）</h2>

<p>来看几个使用案例：如何借助 个人知识库文件 作为外脑，用方法论指导我们正确做事？</p>

<p>DeepSeek 确实很好用，但关键还是会不会提问。</p>
<p>如果不会提问，AI 再强也帮不上忙。</p>

<p>除了花时间学习提示词，更快的方式是本地备一份提问指南，让 AI 指导你该怎么正确提问，这样才能真正发挥它的价值！</p>

<p><img src="img/3f8daf3638a31201a31654123797ebb6.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/RfPHbJMpuodWydxrtzLcrhabnug/"/></p>

<p>AI 借助知识库内的 DeepSeek 指导手册，预判了我可能想问的问题，以及建议的正确提示词格式。</p>

<p>从回答中可以发现，AI 不是依据自身语料库回复，而是基于知识库内容回复。</p>

<p><img src="img/a64e265e9ceaf912404cd46bef52afdf.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/UjUMbVfZVoqkSmxBEUPcG3BenZe/"/></p>

<p>当然，我们也可以直接搜索知识库的原始信息，从而快速查询信息。</p>

<p><img src="img/d7ad58af8d4fa48b8ef24448880529fd.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/OOUZbFmybo5UchxxfCHcwKbpn9I/"/></p>

<h2>二、API  搭建知识库</h2>

<p>如果本地数据不涉密，还想获得最佳使用效果，那肯定得选满血的 DeepSeek R1 模型。</p>

<p>我们来看看怎么利用 API 用上满血的 R1 模型（671 B）。</p>

<p>1、先下载一个叫 Cherry Studio 的软件。</p>
<p>地址： https://cherry-ai.com/download</p>

<p><img src="img/a2dcdc60dd6404dda3951f472855e0dd.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Y2NkbgEN6owlqpxp8CIcxBNRnEh/"/></p>

<p>2、登录/注册「硅基流动」，新用户会赠送 2000万 Token 额度。</p>
<p>地址：https://cloud.siliconflow.cn/i/TAAOvaXg</p>

<p><img src="img/05070250388e5c77db4f84cdd7d7899e.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/JLtLbDWxIo0K4mxvEp0csC9onBf/"/></p>

<p>3、来到 API 密钥生成界面，创建或者复制已有的密钥。</p>

<p><img src="img/498ed2d6c9143da326bc7647c497f27b.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/WC3dbZLY6oZE9pxr49ec8u6anmd/"/></p>

<p>4、来到 Cherry Studio，配置 API Key。</p>

<p><img src="img/1e53046544e58ca816c6812010aa6230.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/VJPFbcKBUokexZxO1wicPoPnnHc/"/></p>

<p>5、在模型广场首页，排在前两位的就是「硅基流动」和「华为云」合作发布的 DeepSeek R1 / V3 模型。</p>

<p>如果需要推理能力，记得打开并复制 R1 模型的名称。</p>

<p><img src="img/32afbfe001b28eff9e7fa0dc19cdc725.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/ZPt5b3cL9oCmPdx4jrpcmTLKn8A/"/></p>

<p>6、在模型服务的硅基流动下方，添加 R1 模型。</p>

<p><img src="img/34603e9423eef3d5119f44a7977f68f2.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/QRGobxsTcoW27IxVobpcuuSmnFf/"/></p>

<p>7、记得点击检查，测试下 API 是否可以正常访问。</p>

<p><img src="img/0f5455c798e08ab29eab60911a438e13.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/PJkeb6cK1omxvkxTg1nckDo5n9x/"/></p>

<p>8、现在对话模型有了 R1，还缺少一个嵌入模型。</p>

<p>嵌入模型的主要作用是将本地文件的内容转换成有意义的数字，存储到向量数据库中。</p>

<p>在用户提问时，利用 RAG 技术在数据库中搜索到相似答案，最终回复用户。</p>

<p>过去我有通俗解释过 RAG 技术，大家如果不了解，可以回头看下：</p>

<p>我们再配置一个向量模型：BAAI/bge-m3，如果希望搜索的精准度更高，可以选择 Pro/BAAI/bge-m3。</p>

<p><img src="img/aa1811c0b4ac4acbb8a3a8409ceebb73.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/TmUAbT19sofYnUxXNKZcmk6JnTb/"/></p>

<p>按照同样的方式配置到 Cherry Studio 中，这里不需要点击检查。</p>

<p><img src="img/cf1d5ef5b1105737754e9d5d3659b0fd.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/UFG4bHpOGocJIdxpySVcmIJdnuh/"/></p>

<p>9、在 Cherry Studio 创建知识库，选择刚才配置的嵌入模型，这样就会自动利用对应的模型来向量化数据。</p>

<p><img src="img/19fec675ab70af1e0f9fcbe020fe9617.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Ncb2bMESioOM18xLqp7c0bnXnUb/"/></p>

<p>10、上传本地文件进行向量化。</p>

<p>如果本地 PDF 文件是 扫描件、手写件，或者带有复杂的表格 和 数学公式，解析效果会很差，甚至无法解析。</p>

<p>遇到这种情况，建议配合过去我介绍的 PDF 转结构化文档 的方案来使用！！！</p>

<p>这样才可以正常回复知识库的内容：</p>

<p>如果追求执行比，推荐使用 Doc2x：https://doc2x.noedgeai.com?inviteCode=4A6KOD</p>

<p>如果希望更加稳定，那么可以考虑 Textin ：https://www.textin.com/market/detail/pdf_to_markdown</p>

<p>当我们上传文件后，箭头指向的图标如图所示，则代表向量化成功。</p>

<p><img src="img/da17e69503a989e351e4011b252f257a.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/VaRBbkjfqo72K4xGTdbcKBcKnUg/"/></p>

<p>11、测试使用，这一步添加助手，并选择刚配置的 满血 R1 模型。</p>

<p><img src="img/cc5aacd8995152f12ee032d850721295.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/AObXbZCVaoQvtcxO75IcfgJFnMc/"/></p>

<p>如果不想每次在添加助手时选择模型，可以将它设置为 默认模型。</p>

<p><img src="img/3badeb6bfba4f7aab9040043cd86aa36.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/E27NbLbBJoO8K7xb2OOcHYHqnmg/"/></p>

<p>我们来测试一下，发现 DeepSeek 已经开始深度思考了。</p>

<p><img src="img/5827bd066564fc62c70ea562191af283.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Uy8bbMEJco4LgHxjABTcjb0enSb/"/></p>

<p>AI 回复的答案和原文一致。</p>

<p><img src="img/21318595bcc73cd0386e8fb436cddafd.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/DF28bo3Gzopwz0xLfFMcwzQmnsf/"/></p>

<p>原文内容：</p>

<p><img src="img/04dded99ed8aac65261e2a6a0650d85e.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/E824bQAXboiSnUxKosyc8Aepntc/"/></p>

<h2>三、本地部署搭建知识库</h2>

<p>如果只是想 简单体验，或者本地算力充足、希望保护数据安全，那么可以考虑 本地部署 的方案。</p>

<p>1、访问 Ollama 官方地址：https://ollama.com/download，下载软件。</p>
<p>建议下载最新版本 Ollama，个人踩坑经历：旧版本安装 R1 后可能无法正常使用。</p>

<p><img src="img/d3c1730e3ab7095d9ca6977b43c51707.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/IWdSbKxaWoW0aHxmdivc9HD7nSd/"/></p>

<p>2、双击运行 Ollama 后，打开命令行，运行需要安装的模型（参数越大，显存要求越高）。</p>
<p>地址：https://ollama.com/library/deepseek-r1</p>

<p><img src="img/54a625a2923b657866998d93e51608e7.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Kwp9b7E79oHMQ4xlei6cGTLCnYm/"/></p>

<p>如果没有 GPU，建议选择 1.5B，运行相对轻量。我这 4G 显存 勉强能跑 8B，但速度较慢。</p>
<p>有朋友用 RTX 4090 测试 32B，效果和速度都不错。大家可以参考这个梯度，根据自己的硬件选择合适的模型。。</p>

<p>下载并运行成功后，就可以和 DeepSeek R1 对话啦。</p>

<p><img src="img/26d1613c07632c65101ae13c433ceb2b.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/TnG8b7WsOoeTlYx45SXcBgZDnHe/"/></p>

<p>当然，我们可以用 Cherry Studio 作为本地 R1 模型的 UI 界面。</p>

<p>打开软件的配置，选择 Ollama，在管理按钮中选择自己部署的模型。</p>
<p>如果选不到，就手动添加模型，API 秘钥填不填无所谓）</p>

<p><img src="img/30b3dc8bc2404617cb3e018614e28e56.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/MuPPbF3L9o9qn2xpCCtcikp5n4b/"/></p>

<p>最后点击检查，测试下网络连通性，出现连接成功即可。</p>

<p><img src="img/2f6e77ce544e4bbb56416cab6b2b6728.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/FUwGbMkVqoSegexGlWXcS49mnwM/"/></p>

<p>接下来就可以在添加助手时，选择本地部署的 R1 模型啦。</p>

<p><img src="img/9d39ef56cbd53428f3ab002cd7d17d80.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Dc5hbBOSoofVyNx48m1cOJeonOc/"/></p>

<p>再测试使用一下，答案与原文一致，搞定~</p>

<p><img src="img/8a4b7181b7f9a18d5a99842a22a41515.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/Q8qabFE8yo1VTZxtp73cNwlZnSc/"/></p>

<p>因为我用的是 Mac，所以没测试 Windows 设备。不过两者区别不大，大家可以自行尝试下。</p>

<h2>四、总结</h2>

<p>看到这里，相信你已经找到最适合自己的 DeepSeek 个人知识库方案了。</p>

<p>如果你和大多数人一样，选择使用官方 API ，那就不用再为性能和本地硬件资源发愁；</p>

<p>如果你恰好有充足的算力和技术储备，本地部署也是个不错的选择。</p>

<p>不过，在整个过程中，我想和你分享的不仅仅是这些技术细节。</p>

<p>而是一个中国团队能做出世界级大模型，一个需要 +86 才能注册的大模型。</p>

<p>很庆幸，我们能作为中国 AI 领域技术进步的见证人。</p>

<p>当然，暂时的领先不是终点。</p>

<p>但 DeepSeek 给我们带来的，是“中国也可以”这份信心。</p>

<p>这，才是我们真正要守护的希望。</p>

<p>我是 🐼 熊猫 Jay，希望本次分享能有所帮助。</p>


