<h1>AI写作原理拆解：一文吃透GPT底层原理和使用误区，提高写作质量（含视频讲解）</h1>
<blockquote>来源：<a href="https://y0arjkskpp.feishu.cn/docx/W9mjd9hoUoBY8TxAs0Hc25Wwnih">https://y0arjkskpp.feishu.cn/docx/W9mjd9hoUoBY8TxAs0Hc25Wwnih</a></blockquote>
<h1>引言</h1>
<p>我之前帮助很多同学检查他们用AI写作的质量问题，我发现有很多问题的根本是对大语言模型的基本原理不理解，导致使用AI的时候犯一些低级错误。</p>
<p>如果你只是把AI当一个聊天机器人，那可以随便聊。但如果要把它当成是强大的生产力工具，那就必须得了解清楚其原理，这样才能把它的能力发挥到极致。</p>
<p>最主要的是，了解原理能够让你明白AI的能力边界，避免让AI做出超出它能力的事情，从而避免犯低级错误。这很重要。</p>
<h1>大语言模型原理</h1>
<h2>什么是大语言模型</h2>
<p>我们写作用的AI属于大语言模型（LLM，Large Language Model），它是AI的一种类型。AI也就是人工智能，它的类型有很多：下围棋的AlphaGo是AI，人脸识别是AI，抖音推荐算法是AI，AI画图也是AI。这些AI都不属于大语言模型。我们写作用的ChatGPT、Claude、Kimi、通义千问这些属于大语言模型。</p>
<p>大语言模型，顾名思义，它是处理自然语言的（自然语言指的是人类从自然界演化出来的语言，也就是我们平时说的语言，它是相对机器语言、形式逻辑语言这些人类发明出来的语言的）。它是使用海量的文字，准确地说是互联网上能搜集到的所有文字，训练出来的，所以叫大模型（准确地说这个“大”是指参数多，但这里就不展开说什么叫参数了）。</p>
<p>GPT（Generative Pretrained Transformer）是一种大语言模型的算法，由于ChatGPT的成功，现在的大语言模型99%都是用的这个算法。其实大语言模型还有别的算法，比如BERT，只是效果不太好，所以没有普及。</p>
<h2>大语言模型是怎么输出的</h2>
<p>大语言模型能够写出来文字，本质上不是因为它真的会思考，而是因为它会“猜”。它的工作原理其实非常简单，就是用全互联网上所有能搜集到的文字把它训练一遍，然后当你跟它说话的时候，它就能猜出来下一个字要说啥。也就是说，它的底层本质是概率和统计。</p>
<h2>大语言模型是怎么记住之前对话的</h2>
<p>大语言模型本身是没有记忆功能的，它之所以能记住之前的对话，原理其实非常简单粗暴，就是把之前所有的聊天记录全部发给它。</p>
<p>举例来说，假如第一次你发给AI的内容如下：</p>
<pre>[
  {"用户": "世界上最高的山是什么山"}
]</pre>
<p>AI给你的回答是：</p>
<pre>{"助手": "世界上最高的山是珠穆朗玛峰"}</pre>
<p>那么第二次对话的时候，你实际上发给AI的是下面的全部内容：</p>
<pre>[
  {"用户": "世界上最高的山是什么山"},
  {"助手": "世界上最高的山是珠穆朗玛峰"},
  {"用户": "第二呢"}
]</pre>
<p>假如AI回答“乔戈里峰”，那么到了第三次对话，则要发送下面的内容：</p>
<pre>[
  {"用户": "世界上最高的山是什么山"},
  {"助手": "世界上最高的山是珠穆朗玛峰"},
  {"用户": "第二呢"},
  {"助手": "乔戈里峰"},
  {"用户": "第三呢"}
]</pre>
<p>由此可见，随着对话的增多，每次发送给AI的内容其实是越来越长的。</p>
<p>这也产生了一个推论：单次发送一个很长的内容，和多轮对话，这二者对AI来说效果是差不多的。</p>
<h1>大语言模型的局限性</h1>
<h2>数学能力/逻辑能力非常差</h2>
<p>因为AI并不是真的会思考，而是靠直觉猜，所以它的数学能力的本质是“依靠经验蒙”。有时候你看起来它会做数学题，这个本质上是因为它在训练过程中读了大量的数学书，能够按照概率猜出来答案。</p>
<p><img src="img/0d8f5f1e9bb59182b3cefa90aa76c5dd.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/WBSIbwYSvoPtdix1YvNcj4Fynkh/"/></p>
<p>尤其是当你让AI写特定字数的文本的时候，它写出来的字数经常是错的。你让AI去数某段文本有多少字，通常也是错的。所以写文章的字数控制不要依赖AI。</p>

<h2>输出的文本不能太长</h2>
<p>根据前面的原理可以知道，大模型本质上是通过前面的所有字来猜下一个字要输出啥，所以越往后猜，肯定就越不准确。所以输出的文本越长，质量会越来越差。</p>
<p>大模型的输入和输出能力是不对称的。举例来说，下面是Deepseek大模型的官方文档里的截图：</p>
<p><img src="img/084e0e69de40abaa0edcf6a4be1fd98e.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/G7ljbIdqmo4CI9xnmeXcoDgrnHc/"/></p>
<p>我们可以看到两个特点：</p>
<ul><li>输入价格比输出价格要便宜很多</li></ul>
<ul><li>输入的上下文长度要比输出的长度要长很多</li></ul>
<p>因此，不要一次性让AI输出太多。</p>
<h2>输入的文本太多，它会忘记前面的</h2>
<p>输入的文本也不能太多，原理有两个：</p>
<ul><li>大模型毕竟是代码，就像你的电脑打开一个大的文件和一个小的文件，对电脑来说肯定是打开大的文件更费劲。所以输入如果太多，大模型的处理质量会变差。</li></ul>
<ul><li>大模型是凭借概率来猜下一个字，所以越靠后的字肯定优先级越高，越早的字优先级越低。所以太早输入的内容会被大模型忽略掉。</li></ul>
<ul><li>虽然目前大部分大模型都能支持128K的上下文（大概有几万字的中文），但是实际上你用的平台为了省钱，如果你对话的轮数太多，它在实际发送给大模型的接口之前会对你之前的内容进行压缩，很多细节因此就会被省略掉</li></ul>
<h2>输出的风格依赖于输入的上下文</h2>
<ul><li>你设定的是学术风格，那么就会输出学术风格</li></ul>
<ul><li>你设定的是儿童风格，那么输出就会很幼稚</li></ul>
<p>这也是为什么提示词的正确使用非常重要。你的提示词太简单，那么输出很可能就会很普通甚至AI味很浓。你提示词越精确，它就越能输出符合要求的内容。</p>
<p>这同时也说明了一个问题，就是不同的任务，不要混杂在一个对话当中。每个不同的任务，应该开启不同的对话。</p>
<h2>你上传文件并不意味着它会完整地阅读全文</h2>
<p>目前对于上传的文件，大部分情况下使用的是一种叫做RAG的技术。这种技术能够把大文件给向量化（非技术同学不用管什么是向量化），向量化的文件能够方便AI进行检索。</p>
<p>它的好处是，如果你想问AI这个文件里有没有某个内容，AI可以帮你从里面读取到相应的内容。</p>
<p>它的缺点是，它实际上并不是完整地读了整篇文章。</p>
<p>因此，对于上传的文件，你可以问AI：</p>
<ul><li>这篇文章里有没有关于xxx的内容</li></ul>
<p>你不可以问AI：</p>
<ul><li>帮我检查一下整篇文章的结构是否清晰</li></ul>
<ul><li>它有可能会回答“我发现第三章似乎没有写结论”，这种情况可能是把第三章分成了多个片段导致的</li></ul>
<ul><li>帮我对整篇文章进行改写</li></ul>
<p>如果文章本身不是特别长（中文不超过3000字，英文不超过1500单词，对AI来说是发挥比较好的字数。超过这个字数当然也可以，但是AI的能力会下降很多），并且你想让AI帮你读整篇文章的话，最好的办法还是直接复制粘贴到对话框中，而不是依赖文件上传功能。</p>
<h2>有一些明显的语言特征</h2>
<p>如果没有用提示词进行限定，大语言模型会默认按照它最喜欢的输出方式来输出。这种情况下有一些很明显的特点，让人一眼就能看出来是AI写的。</p>
<p>有些很明显的特点比如：</p>
<ul><li>喜欢用列表</li></ul>
<ul><li>喜欢用小标题+冒号</li></ul>
<ul><li>喜欢用“首先、此外”等连接词</li></ul>
<ul><li>喜欢在最后进行总结</li></ul>
<p><img src="img/de213f4420c31883926dde374780c8c5.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/SuXlbRvdkoMOC1xIS7acOCW8nJg/"/></p>
<p>所以，哪怕是你不考虑系统检测AI率的问题，也得至少确保不要让人一眼看出来这是AI写的。（至于如何让系统检测不出AI率，这个我会在其他的教程里面讲）</p>
<h1>大语言模型的正确使用方法</h1>
<h2>一定要人工检查</h2>
<p>到目前为止，大语言模型只是人类的提效工具，一个扩展，而不是替代。它仍然会犯很多低级错误，因此必须得依靠人类进行兜底。</p>
<p>用AI写的东西一定不要不做检查就直接交付，一定要做检查。</p>
<h2>一定要分段处理</h2>
<p>大语言模型没法一次处理很长的文本，一定要分段处理。</p>
<p>就我的个人经验而言，要保证AI对输入的理解能力和对输出的质量保证，字数最好是下面这样：</p>
<p>中文：</p>
<p>每次发给AI的输入不要超过2000字，每次让AI写的内容不要超过500字。</p>
<p>英文：</p>
<p>每次发给AI的输入不要超过1000单词，每次让AI写的内容不要超过300单词。</p>
<h2>定期重置上下文</h2>
<p>这里面包含了两个道理：</p>
<ul><li>不同的任务要用不同的对话，不要在一个对话里讨论不同的事情</li></ul>
<ul><li>如果某个对话太长了的话，AI的能力会越来越差，这种情况应该重新开启一个对话。</li></ul>
<p>对于对话太长的情况，开启新的对话肯定能够让AI更好地处理。但是这里面有个问题，就是在新的对话里，AI根本就不知道之前的对话里的内容，这时需要你总结一下之前对话的内容，让AI重新建立起上下文，知道你要干什么。</p>
<p>因此，同一个对话的好处是不需要重复对AI下指令，AI能够根据之前的指令进行执行，坏处是时间长了，AI会忘记最初的指令。因此要做好取舍，判断该不该重新开启新的对话。</p>
<h2>用提示词框定好上下文</h2>
<p>提示词工程的意义就在于此。你表达的越精确，AI的表现就越符合预期。</p>
<p>一定不要偷懒，只用一两句话来告诉AI应该干啥。应该尽可能地描述清楚你要做的事情。</p>
<p>如果有别人一定实践好的一套提示词，当然最好是直接复用，这样比自己从头写效果要好。</p>
<p>但也不能完全依赖别人的提示词，要自己明白原理，按照具体情况具体分析，生搬硬套有时候会不符合当时的场景。</p>
<h2>让它一步一步思考</h2>
<p>这个可以说是最强的大语言模型提示词了，这个经过了大量的实践证明能够大幅提升AI的能力。原理其实就是之前讲的原理，也就是上下文越清晰，AI猜中下面输出文字的能力就越强。</p>
<p><img src="img/56d342c3231c56bbcfd5ca5206f6b493.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/D3qobwT6sosCowxATLic2guKn8e/"/></p>
<p>“请你做个深呼吸，一步一步思考”，大量实验证明，提示词里加上这一句能够让大语言模型的能力变强。</p>
<p>很多人虽然知道这个技巧，但使用的时候有个误区。这个误区就是不明白一个道理：没有明显的思考过程，等于没思考。</p>
<p>比如下面这个提示词：</p>
<p><img src="img/a56171f1ad0b7a1973a2400905c353ea.png" data-original-src="https://internal-api-drive-stream.feishu.cn/space/api/box/stream/download/v2/cover/HXqCbQGH4o7wQoxTamycyR1rnHh/"/></p>
<p>这个提示词虽然前面加了“请你一步步思考”，但是后面说“不需要向我解释”，那么其实这个“一步步思考”的效果就会大打折扣。</p>

<h1>附录：目前哪些大语言模型很强（定期更新）</h1>
<p>了解这些来帮助大家来选择合适的模型，确保大家用到的都是最好用的。这部分内容具有时效性，当前的内容更新时间是2024.12.29</p>
<p>名词解释：</p>
<p>多模态：有两种以上的数据类型（文本、图片、音频、视频等）处理能力。比如大语言模型一般都是处理文字的，如果它还能识别图片，就说它有多模态能力。</p>
<h2>常见大模型（不完整列举，主要针对常用的）</h2>
<h3>美国</h3>
<h4>OpenAI公司</h4>
<p>大语言模型的祖师爷。</p>
<p>ChatGPT系列</p>
<p>ChatGPT 4o：目前ChatGPT的主流版本。o表示omni，意思是全能，主要指它的多模态能力。最新版是2024-11-20</p>
<p>ChatGPT 4o mini：mini的意思就是低配，比4o价格更便宜，速度更快，能力上差一些，主要用来处理一些简单任务</p>
<p>（但有个很坑的一点是，现在的ChatGPT为了降本增效，有时候会把ChatGPT 4o偷偷降智成ChatGPT 4o mini，所以有时候4o的能力会差的离谱，建议大家避坑。）</p>
<p>o1系列（具备逻辑思考能力）</p>
<p>o1：正式版于2024-12-17发布，之前发布的预览版叫o1-preview。这个模型具有思考能力，特点是要花很长时间思考，价格也很昂贵。经过长时间思考以后，确实具备了一定的逻辑能力，弥补了普通大语言模型逻辑能力差的问题。</p>
<p>o1-mini：o1的低配版，也就是思考的时间相比o1大幅减少，所以价格便宜很多。逻辑能力比普通的ChatGPT 4o要强一些。（注意，这个名字不要和ChatGPT 4o mini混淆！ChatGPT 4o mini的能力非常差！）</p>
<p>o3：o1的下一代，发布会只公布了性能，但是还没开放给大众使用，预计明年开放。据说能力超过了人类的博士水平，但价格极其昂贵。之所以没有o2，是因为这个名字被别的公司用了。</p>

<h4>Anthropic公司</h4>
<p>OpenAI的创始人有一大半来了这个公司</p>
<p>Claude 3.5 Sonet：目前Claude的主流版本，对标ChatGPT 4o，但实测能力比ChatGPT 4o要强。推荐大家优先使用这个模型。最新版是2024-10-22</p>
<p>Claude 3.5 Haiku：低配版，对标ChatGPT 4o mini</p>
<p>Claude 3 Opus：Opus是能力最强的系列，但可惜一直没出Claude 3.5 Opus，目前最新版还是3.0</p>

<h4>Google公司</h4>
<p>Gemini 2.0 Flash：2024-12-11放出了免费测试版，能力超过了ChatGPT 4o和Claude 3.5 Sonet，但还是测试版，不太稳定。</p>
<p>Gemini 2.0 Pro：2024-12-06放出了免费测试版，能力仅次于o1，但还是测试版，不太稳定。</p>
<p>Gemini 2.0 Flash Thinking：2024-12-11放出了免费测试版，能力对标o1，但还是测试版，不太稳定。</p>

<h4>X公司（原Twitter）</h4>
<p>Grok2：2024-12-12发布，能力不突出，无需关注</p>

<h4>Meta公司（Facebook）</h4>
<p>Llama 3.2：最强的开源大模型之一，但不考虑自己部署开源代码的话可以不关注。</p>

<h3>中国</h3>
<h4>深度求索公司</h4>
<p>Deepseek V3: 2024-12-26发布，目前最强（不只是中国最强）开源大模型。能力上超过了ChatGPT 4o、Claude 3.5 Sonet、Gemini 2.0 Flash。唯一缺点是不支持多模态，识别图片的能力很差，但对于AI写作来说影响比较小。</p>
<p>而且是免费的，不需要翻墙，网址：https://chat.deepseek.com/</p>

<h4>月之暗面公司</h4>
<p>Kimi：目前国内最受欢迎的大语言模型，非常好用，免费，尤其是搜索功能挺好用的。日常可以用这个。它比Deepseek擅长识别图片，而且用户界面非常友好。https://kimi.moonshot.cn/</p>

<h4>阿里巴巴公司</h4>
<p>通义千问 2.5：之前是国内最强的开源大模型，现在暂时被deepseek超越。</p>

<h4>字节跳动公司</h4>
<p>豆包：emmm，怎么说呢，营销做的很好，用户功能很多，也很友好，但是大模型的质量还是不够好。</p>

<h4>百度公司</h4>
<p>文心一言：国内最早的大语言模型，发展了这么多年还是*</p>

<h3>法国</h3>
<p>Mistral：除了美国、中国以外做的最好的大语言模型了。免费使用，也有网页搜索功能，而且不用翻墙，如果临时想搜索一下国外的论文又不想翻墙，可以试一下这个。网址：https://chat.mistral.ai/</p>

<h2>怎么选择</h2>
<p>我目前用的最多的是Claude 3.5 Sonet。至于Deepseek V3刚发布，虽然能力很强，但我没大量测试过，推荐大家可以用用看，毕竟免费且不用翻墙。</p>