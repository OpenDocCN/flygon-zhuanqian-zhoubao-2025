<h1>6 年老圈友复盘：用 AI 改造业务的 2 年实战 —— 从替代 30 人审核团队到支撑 50 国运营</h1>
<blockquote>来源：<a href="https://q5hwxkwgss.feishu.cn/docx/Aw0FdFCnQoXQf9xwae6cbNsBnbg">https://q5hwxkwgss.feishu.cn/docx/Aw0FdFCnQoXQf9xwae6cbNsBnbg</a></blockquote>
<p>圈友们好，我是陈亮，今年 6 年老圈友，base 成都</p>
<p>这篇文章，我想复盘一下自己从 2023 年 5 月开始，通过把 Ai 引入到公司的业务中，对不同业务的改造的经历和细节。这个中间我主要介绍两个主要的场景，一个是通过 Ai 替换了公司接近 30 个小语种的审核外包团队的工作，第二个是把 Ai大模型引入到内容信息流改造，全自动化拓展至 50 个国家的内容运营工厂。</p>
<p>这篇文章比较长，信息密度也比较大，但是如果你对 Ai 全自动化内容运营、A业务流程改造感兴趣，耐性看完，你会有收获的。</p>

<h1>成果</h1>
<p>先说一下最终的成果：</p>
<ol><li>对于 AI 替换小语种外包团队，按照在成都的小语种薪资大概在 8000 左右，大概就是 24W 一个月的人工成本。但是接入 AI 之后，一天原有工作的替代成本不到$100，并且把原来有限的审核内容，拓展成为了不受限于精力、人员管理等无限的内容审核量。（人员的管理、团队的配合、调班大家都知道这里面的成本才是巨大的）。</li></ol>
<ol><li>今年把 AI 运用到出海内容运营上面，原本国外内容运营受限于所在出海国的本地化人配置，但是当 AI 可以做这个事情的时候，做多国家内容运营和分发边际成本几乎为 0，可以低成本拓展更多国家运营，重要的是把这一套基于 AI 运营的工程化机器搭建稳定。</li></ol>
<p>那么接下来，就和大家一起分享一下，我们团队一起最近这一两年在 AI 上面做的事情；</p>

<h1>缘起：为何要做 Ai 工作流</h1>
<p>2022 年8 月到现在，入职这家做非洲市场海外信息流的团队做事情。当时终面快结束的时候，CEO问我，你还有什么问题需要问我，“我如果来到这家公司，你希望我可以给公司带来什么”，这是我当时的问题，也是我在生财学到的思维，提供什么样子的价值给你的客户，利他及利己，这也是我这几年在公司里面做事的原则。</p>

<p>因为是一名全栈开发，进去之后做了很多提效的工作，也帮业务做了很多自动化的事情。但因为是技术的岗位，虽有业务超盘手的心，但是只能做业务执行者的事情，最多提供一些技术的视角，在原有的互联网生态系统里面，技术和业务的结合体的岗位是不存在的，或者说很少，你只能选择技术或者业务。</p>

<p>2022 年 12 月，当我在生财的风向标里面看见 chatGPT 。试用之后，我感觉到了这是一场新的力量，只是这个信念不够坚韧，因为没有看清底层的实现，三环内现在是属于教育不知道它可以做什么事情，在接下来半年时间，学习大概的实现原理，各种海外的技术分析，生财里面的各位老师各显神通。我就知道这一次我可以以一个业务操盘手的角色来做些事情了。</p>

<p>一个新的技术出现之后，一定会构建一个新的生态系统，这个新的生态系统里面，各个不同的生态位等着被填补，而这个时候，勇敢的人是能够获益最多的。</p>

<p>当时的目的很纯粹，要学到一身出海的本领，要在这个公司一身业务操盘手的能力，同时希望相互赋能，共同成长。2023 年 6 月，我开始利用 openai 的接口在一些业务和内部非关键主路径的业务做一些事情，这个过程拿到了一些不错的结果（这个有机会后面分享），在多次迭代的过程中，升级接入了企业级的 openai 服务接口（通过签国内的 Azure 代理公司），也完成了多次 Ai 在工业化的使用，积攒了一些认知，更加获得了公司首席 AI 架构师的称号，此时再做事情，也算是师出有名了。</p>

<h1>业务 AI涅槃之路</h1>

<p>背景：我们公司因为是做信息流业务的，DAU 大约有 4000 万，可以理解为是非洲以及中亚的今日头条。内容属于通过各种渠道的热门内容和本地网站抓取而来，内容语言种类繁多，包括英语、阿语、法语、葡语、阿姆哈拉语、斯瓦西里语，同时在多个非洲和中东国家运营。</p>
<p>原因：内容可能涉及到穆斯林文化等宗教信仰以及各国涉政问题，导致 APP 最后在应用商店下架的风险。</p>
<p>现状：所以公司有一个接近 30 人的小语种审核团队对所有消费比较好的内容做内容审核判定，以及一开始只运营了中非和东非的国家，并且在各个国家还要保留对应的内容运营团队。（小公司也训练不出来自己的内容审核模型，三方模型也适应不了很多不同国家的特质需求）</p>

<p>问题点：</p>
<ol><li>内容风险不可控：</li></ol>
<p>第一个是就算是 30 个人的审核团队，为了内容合规，负荷拉满，也只能审核一些高热的内容，我们最开始每天文章的入库量是4 万篇，小视频的入库量是 5 万。</p>
<p>一个人每天最多审核的内容按照平均统计文章 300篇或者小视频 1000 个。30 个人最多也就只能覆盖小部分内容，并且对于审核这件事情，他是一个非标评判标准，标准再细化，对于不同的人可能最后也会有不同的认知。</p>
<p>这就相当于始终会有一部分风险内容会在线上被人持续消费看到，这就相当于一把达摩克利斯之剑悬在头顶，不知道什么时候落下来，这对于做业务而言，是很难受的。</p>

<ol><li>业务拓展困难：</li></ol>
<p>这个点上面提过，当我们想要把内容再多做一个国家的时候，需要审核的内容量上涨，同时需要本地化内容运营人员，而对于跨国团队搭建这件事情，做过出来业务的老板应该是明白其中的苦，特别实在非洲这个素质教育不太完备的地方，人才密度底，找到合适的人更难。</p>


<h2>内容审核改造（用 AI 全自动化改造 30 人的多语言内容审核工作）</h2>

<p>2023 年下半年，就持续以 AI 首席架构师的名义和审核的运营管理同学聊这个事情，为什么不用一些 AI 为审核同学分担一些业务量，这样就可以把审核文章的数量扩展到更高。12 月，开始搞事情。</p>
<h3> 第一步：最小 MVP 验证最小可行性</h3>
<p>2023 年 12 月份的时候，当时最好的大模型是 GPT4，只支持图片和文字，所以在当时，我们也不知道后续会有更多模态这种模型的出现。</p>

<p>所以第一步可以通过接入文本模型能够把 4 万篇文章分摊部分工作量，如果这套路可以成立，再继续推进图片。</p>
<p>因为一篇文章，构成就是文字和图片，所以我们的方案就是拆分文章的内容：</p>
<ol><li>根据不同国家的标准，把标题、介绍、文字内容结合我们的审核提示词喂给模型，让模型来判断是否违规。</li></ol>
<ol><li>如果这个时候文字已经违规，就直接下架文章</li></ol>
<ol><li>如果文章文字没有违规，我们改造了文章审核人员的工作流，文章就只看图片是否有色情、暴力等；</li></ol>
<ol><li>如果图片违规，人工再下架。</li></ol>

<p>这一套工作流改造下来之后，就需要持续迭代提示词修改细节来演进，但是演进的过程需要数据反馈；</p>


<p>所以我们保留了现有人工审核文章的方式继续运营，同时这一部分内容双跑改造之后的工作流，只评估最后的效果，不做真正的下架动作，在这个过程中评估 AI改造之后的准确率和召回率；</p>

<p>准确率:</p>
<p>定义：所有被系统标记为违规的内容里，真正违规的比例。（评估误伤有多少）</p>
<p>换句话说，就是系统抓出来的“坏人”里，有多少真的是坏人。</p>
<p>召回率：</p>
<p>定义：系统把所有真正违规内容抓出来的比例。（评估真正违规的是否漏放）</p>
<p>换句话说，就是所有的“坏人”里，有多少被系统抓到。</p>
<p>对这个标准感兴趣的可以详细问一下 AI，这里面就产生了误伤率和漏放率</p>
<p>我们通过以人工评判结果为标准的结果集来评判 AI 的结果，最终在迭代了多次之后，发现对于纯文本文言，在我们这个场景里面，各个指标最高的是 GPT3.5 1106，这是我们当时的第一版可行的提示词：</p>
<pre>             
您是一个内容安全审核专家，专门针对各语言的文章进行风险研判。用户将粘贴一串文本和要求，你将根据提示和文本给出判断结果。
对于这篇文章，请您:  
1. 按照输出格式输出，不要加入其他回答信息。 
2. 判断这篇文本是否违规。
###
违规类型有：
| 01 |暴露人类敏感部位。**豁免：强奸案件、医疗报道** |  
| 02 |主旨展示或描述情趣服饰、情趣玩具、精液| 
| 03 |暴露内衣内裤 |   
| 04 |借用普通物品模仿性爱动作、姿势 | 
| 05 |富有性意味或引起用户低俗联想的内容 |
| 06 |有衣物遮盖的生殖器勃起 |
| 07 |分享或宣扬色情网站及视频。**豁免：事件报道** |
| 08 |详细描述人类隐私部位或女性胸部。**豁免：医疗报道**|
| 09 |主旨讨论性生活，如体位姿势、一夜情、自慰手淫、性爱技巧等|
| 10 |任何关于LGBT的文章|
###
3.要求
###
若文章违规则返回“0”且需要说明原因。若不违规或可被豁免，则返回“1”。
###
 
 
You are a content safety review expert, specializing in risk assessment for articles in various languages. Users will paste a string of text and requirements, and you will give a judgment result based on the prompts and text.
For this article, please:
1. Output in the output format, do not add other answer information.
2. Determine whether this text is in violation.
###
The types of violations include:
| 01 |Exposing human  private parts. **Exemption:rape cases, medical cases** |  
| 02 |Article subjects showing or describing semen, erotic clothing, erotic toys |  
| 03 |Exposing underwear |   
| 04 |Using ordinary objects to imitate sexual acts or positions | 
| 05 |Content appears with adjectives that easily causes sexual associations or that may lead to vulgar associations |
| 06 |erected penis visible through clothing  |
| 07 |Sharing or promoting pornographic websites and videos. **Exemption: event reporting** |
| 08 |Detailed description of human private parts or female breasts. **Exemption: event reporting, medical cases**|
| 09 |Article subjects discussing sex life such as body positions, masturbation masturbation, sex tips, etc.|
| 10 |Anything about LGBT|
###
3.Requirements
###
If the article violates the rules, return "0" and explain the reason. If it is not in violation or can be exempted, return "1".
###
 
 
tilte:
Armed robbers invade Ogun varsity hostels, r@pe four female students
content:
Nigerians have taken to social media to express their shock and disappointment after a throwback video of popular Nigerian singer Tiwa Savage surfaced online. The video shows CONTINUE FULL READING…  
the singer engaging in sexual acts with an unknown man, causing a stir among fans and critics alike  
Tiwa Savage has responded to the video, but it has sparked a wider conversation about the issue of privacy and consent in the digital age. Many are calling for greater protections for individuals’ personal information and for more responsible use of social media.  
Regardless of one’s opinion on the matter, it is clear that the video has caused a significant amount of controversy and sparked a much-needed conversation about privacy and consent in today’s society.  
The aim of the sex tape was to threaten her career and bring her down.   
Recall that earlier on, Tiwa in an interview with American OAP, Angie Martinez of Power 105.1 revealed that she’s been blackmailed over a leaked sex tape of her with her current lover.
assitant:
{
        "result": "0",
        "Reason": "The text contains a detailed description of a sexual act involving a popular singer, which falls under violation type 02 and potentially type 08"
 }
 </pre>

<p>这个过程中，对于审核提示词和评判标准这块，其实我们有好几种方案来推进：</p>
<ol><li>直接无规则，就只是表示是哪个国家的内容，需要下发哪个国家让模型判断是否违规（输入输出都少，成本最低，效果最差）</li></ol>
<ol><li>给出规则，让模型根据规则判断是否违规，最后给出结果是否违规（输入多，输出少，成本适中，效果不错）</li></ol>
<ol><li>给出不同的各种标签，通过让模型输出文章命中了哪些标签，最后工程手段来匹配标签命中判断是否违规（输入多，输出多，成本最高，效果不错）</li></ol>
<p>最后综合评判，选择了第二种，通过给出规则和标准，让模型判断。</p>

<p>这一步在业务可行性上保证了之后，就开始核算成本，按照审核团队人员的总支出（包含社保、公积金等）计算审核存审核文字的工作量，计算单篇文章文字的人工审核成本。</p>

<p>根据当时选择模型 gpt3.5 1106 的 token 计价计算平均一篇文章 doc 的审核成本，发现在文字这个方面是可行的，虽然低不了太多。</p>
<p>最终在完成了成本可行和能力可能的情况下，我们完成了第一次纯文字的 MVP 版本改造。（具体成本数据敏感就不透露了）</p>
<p>上线之后，通过各种工程的手段，以及用户反馈，一段时间双跑，人员标注不计入上下架，以 AI 结果为主的方式来观察数据，发现持续可行，最后就真正的达到了文章文字审核可行的目的。（这个过程中还涉及到很多并发、配额、效率、模型稳定性的各种工程问题，先按下不表）</p>

<h3>第二步：大胆测试，小心验证，小范围探索的时候可以不控成本</h3>

<p>在第一步达到一个基本可用上线的情况之下，就已经大幅减少了原有审核对于文字部分的工作量，此时原有人工就可以做更多小视频的内容审核。</p>
<p>此时 2024 年春节来临，大家回家过年，按照往年因为海外不过年，所以审核团队的人员保证需要到位，就涉及到很多人员调整补班的问题，因为是三方外包审核团队，就出现了审核标准不太一致。但还切换了文字 AI 审核之后，这个问题变得好解决了，人员只需要图片。Ai 改变业务之后的收益持续浮现。</p>

<p>所以在24 年过完年之后，我们开始了图片审核的调研，当时市面上可以选择的模型是Claude3、Gemini1.5、GPT4，最后在图片方面测评下来数据，数据表现比较好的还是 GPT4V，但是在AI做的过程中遇到了一个好像是无法翻越的困难，有一些图片内容传递给模型之后，会返回说：“我没有发现有可以识别的东西，内容无效”。</p>
<p>因为从一开始在测试图片可行性的时候，就在心里面种下了一根锚，成本比较贵，相比于文本。最后多方排查，甚至最后通过工单联系厂商，最后发现是因为图片模糊。我们信息流下发，会有不同清晰度的图片，我在最开始的时候选择了压缩最狠的图片，就出现了偶现的不可用的情况；</p>

<p>所以，在验证可行性的时候，可以少量不优化成本的情况下验证，链路是通的情况下，再来通过拆解链路，优化成本保证利润率。</p>

<p>最后换上了中等和高等质量的图片测试，发现问题完全解决，同时在准召率上中等质量和高等质量的图片差别不大。</p>
<p>在图片审核准召率可行的情况下，我们开始了新的业务改造：</p>
<ol><li>文章文字 AI 审核，如果违规，直接下架</li></ol>
<ol><li>文章文字没有违规的情况下，图片 AI 审核判定，如果图片违规下架</li></ol>
<ol><li>文字和图片都正常，就正常分发</li></ol>
<p>计算成本完全可控，进行双跑业务线上验证，同样走文字审核的改造方式。流程如下图</p>


<p>这里面其实还有一个问题，GPT4V 图片输入 上下文限一次是 9 张，文章是可能超过 9 张的，这个时候，我们就通过一些分批请求的方式，最后合并结果</p>
<p>最后我们在 2024 年 4 月份的时候，就完成了所有高热文章 AI 审核，当时每天的成本大概在 $150左右，相对于人工是低很多了，腾出来的人工可以全力去做短视频的审核。</p>
<pre>             
你是一个内容审核专家，专门针对非洲各国的图片内容进行风险研判。用户将上传一组图片，你将根据提示判断是否违规。
###
违规类型有：
| 01 |暴露人类敏感部位 |  
| 02 |展示或描述情趣服饰、情趣玩具、精液| 
| 03 |暴露内衣内裤 |   
| 04 |借用普通物品模仿敏感部位、性爱动作 | 
| 05 |富有性意味或引起用户低俗联想的内容 |
| 06 |有衣物遮盖的生殖器勃起 |
| 07 |分享或宣扬色情网站及视频 |
| 08 |描述人类隐私部位或女性胸部|
| 09 |讨论性生活，如体位姿势、自慰手淫、性爱技巧等|
| 10 |任何关于LGBT的内容|
| 11 |自杀自残或其他暴力场景|
| 12 |引人不适的画面，如密恐、尸体等|
| 13 |辱骂嘲讽国家领导人|
| 14 |对宗教、种族、性别、国籍等的歧视行为或言论|
###
要求：
1、若内容违规则返回“0”且需要说明原因，若不违规则返回“1”
2、用json格式返回结果</pre>

<h3>第三步：发展眼光看业务，沉淀自己业务标准数据集</h3>

<p>2024 年 5 月，GPT4o 发布，这完全是突破性的革命，速度更快，能力更强，我们进一步改造工作流</p>
<p>之前是文字和图片分开一起发送给大模型，分步判断，其实可能会丢失一些信息的可能性，如果一张比基尼的图片，如果单独图片审核是会下架的，但是它的文字如果是将女性健康的，这个内容在我们人工审核的标准里面是合规的，它属于健康知识分类。</p>

<p>而对于 GPT4o 模型能力的提示，我们可以一起发给他们，让大模型理解，所以工作流就变成了：</p>
<ol><li>图文一起发送给 AI，如果违规，就下架（9 张图片上限仍然存在，通过文本和图片分批发送）</li></ol>
<ol><li>图文没有问题，上架下发</li></ol>
<p>同样的双跑方式，成本核算下来比分开的还低，因为系统提示词会重复在图片和文本提交。流程如下图</p>


<h4>在最合适的时候控成本</h4>
<p>同时在这个过程中，对于图片的计费，openai 有一个计算 tile 贴图的规则：</p>
<ol><li>低分辨率模式：85</li></ol>
<ol><li>高分辨率模式：</li></ol>
<ol><li>512px * 512px为一个 tile</li></ol>
<ol><li>厂商会通过一定的规则缩放图片：</li></ol>
<ol><li>长边超过2048px，要把图片等比缩到长边2048px</li></ol>
<ol><li>短边超过768px，要把图片等比缩到短边768px</li></ol>
<ol><li>长边小于2048px，短边小于768px，不缩放，直接盖</li></ol>
<p>最终token=170 * tile + 85</p>

<p>比如一下的集中情况：</p>
<p>所以，我们根据文章图片的尺寸在保证效果的情况之下，同时缩放为该范围内最经济的方式；</p>

<h4>沉淀自己的业务评测数据，构建起来业务飞轮</h4>

<p>这个时候，我们发现，模型的迭代太快，当时做不了的事情，不一定半年之后做不了，现在承受不了的成本，不一定半年后承受不了，勇敢的拥抱 AI，一定是可以给业务带来革新。</p>
<p>但是面对于不同的模型升级改造，都会有一个问题，效果怎么评估，成本怎么核算，对于效果评估和成本核算在不同的业务里面有不一样的场景，但是面相特定的业务的时候，是应该沉淀自己业务的评估数据集和评估标准。</p>

<p>这个时候只有我们的高消费文章内容才过了审核的，但是还有部分 80% 的内容还处于未质检的情况，风险一直存在，AI 审核流程已通，只是扩量到所有，需要做的就是成本的核算，五倍之后的成本，相比于人工仍旧便宜，所以我们最后全量了审核，把文章内容合规做到了极致，解决了公司最大的一个可能的风险；</p>

<p>此时，我们再复盘发现，公司本来做信息流下发的，需要沉淀一个内容的分类和标签，之前用的自有模型，在北京有 6 到 7 个人做推荐系统，用的开源的框架改的，分发效率低下，为何不直接复用这一套框架，就可以同时做审核、信息流分类、标签定义。</p>

<p>2025 年 6 月再一次升级，通过复用一套工作流，输出文章内容的标签信息，通过做标签信息做分类和审核。此后三个月在多次的迭代中，完成了新的一套标签系统，通过 AB 实验发现数据表现比原来的数据更好。同时对于背景的专门做这块的团队，自然也没有了存在的意义。</p>

<h3>第四步：模型升级带来的可能性</h3>

<p>此时此刻，一天的成本大概在 $800左右，审核团队的工作变成了只审核视频的作用，但是这仍然存在文章的问题，所以我们拆解了一下审核人员的工作，发现也并不是一帧一帧全部看完内容，而是通过几种方式：</p>
<ol><li>看封面</li></ol>
<ol><li>一个视频均匀截取 9 张图，看其中的 9 张</li></ol>
<ol><li>对于有举报的视频，快速拖拽看视频（因为多张图片和封面看不出来）</li></ol>

<p>所以我们拆解下来，至少 1 和 2 是可以做的，当时的 GPT4o 是可以识别图片，给出是否违规，所以还是和之前的流程一样，不过先做第一步，审核封面；跑通之后，再决定是否做第二步，拆分审核 9 张图片。</p>
<p>2024 年 11 月，我们同样复刻之前的改造流程，准备评估的数据标准级，在线下通过提示词调试，批量脚本测试，数据的准确率和召回率达到标准之后，开发上线双跑。</p>

<p>12 月份，所有高消费的小视频封面审核，通过AI 审核完全替代人工。这个过程中，我们准备要去做把一个视频抽 9 张图片出来给到 AI 审核的时候，通过数据发现，在 AI 审核封面违规之后的数据，就已经覆盖了 98% 的违规内容，那么在当时 GPT4o 的成本之下，2% 的收益和风险是否可以承受，所付出的成本和收益，在当下的情况下，是否 ROI 为正，是否有兜底保障。</p>

<p>我们最后决定保留人工审核举报的小视频，通过快速拖拽的方式，只不过这个时候的量已经比较小了，并且我们封面审核之前，人工只审核了高消费的小视频，但是通过 AI 接入封面审核小视频是全量的，这一点也已经决定了举报的量直线下降。</p>

<p>此时此刻，大概是 1 月份左右，按照往常的话，应该是一个高兴的年，但是于我心里，仿佛就像一把侩子手挥向了审核团队的人员们，当我上线了这个功能时，我就已经知道这个团队应该留不下几个人了。历史的车轮滚滚而过，没有任何一个人可以幸免，而我们可以做的就是尽其所能，搭上这辆列车，驶向未来，搭上这辆列车的方法也很简单，相信他，靠近他。</p>

<p>做完这个事情之后，就到了 2024 年春节，春节期间的 DeepSeek 大热，加上我们已经在 AI 上面做的事情，直接让公司层面改变了整个未来的战略目标和方针。而我作为公司第一个把 AI 引入到业务里面的人，自然是已经把握住了这个生态位，公司所有业务上的 AI 相关的业务和事情，我都能够介入，也因为能够介入更多的业务和事情，我自己在业务方面的能力也直线上升。此时此刻，再回想起刚进公司的时候，我问 CEO 的那一句话“我如果来到这家公司，你希望我可以给公司带来什么”，大概也算没有辜负当时的自己，并且可以和公司一起成长</p>

<p>2025 年2 月过完年之后，公司层面对审核团队进行了优化，至此，一个接近 30 个人的小语种审核团队被 AI替代，并且工作量是之前的 7 到 8 倍，成本只是之前的十个人的成本。</p>
<p>2025年 2 月在Google Cloud 上可以被正式使用，我们通过优化提示词，gemini2.0 达到了 chatGPT4o同样的效果，并且成本只是原来的 1/5，相当于是原来两三个人的成本，并且它可以输入视频和音频，理解它的内容。这个能力就可以做很多业务和产品了，我们也基于此做了很多事情，这个后面有机会再聊。</p>

<h2>信息流业务AI化（AI 运营内容，无边界拓展多国家业务）</h2>

<p>之前聊到了一个问题，当我们的内容需要新拓展一个国家的时候，因为不懂对应国家的文化，不知道用户喜欢哪些内容，不清楚哪些事情对于用户而言是一个比较大的重要爆款事件，应该持续关注。因为有爆款的话题内容，就有信息流消费，有消费我们就有收入。</p>
<p>所以，公司头两年做内容就一直只能局限在尼日利亚、肯利亚这几个中非国家，因为这几个国家有本地运营，可以每天基于本地国家的事情来发爆款内容，做内容的运营动作。</p>
<p>在经过去年一年对于 AI 使用上的探索，以及在工程化基础的搭建上已经偏向比较成熟。今年三月份，我们开始了整个信息流运营流程的改造。</p>

<h3>第一步：拆解工作细节，识别固定流程和需要动脑人工参与的流程</h3>
<p>我们在已经有过去年对整个审核业务的改造之后，发现了一个问题，对于所有的工作，都可以抽象 SOP，只是在 SOP 的过程，哪些需要人来决策，需要人来思考，做出下一步的动作。</p>
<p>下一步动作之后，又需要做决策和判断，以此循环。当拆解的业务流程足够细的时候，就是一个执行动作+一个思考的，多个这样的组合到一起，这也就是现在的 Agent；</p>

<p>不过 Agent是给定一个大目标，模型拆解任务，制定计划，执行，复盘，再做下一步计划执行，以此达到目的。但是对于特定的业务场景，模型是不清楚具体你的业务细节，所以在特定的业务领域最好的大模型用法是：</p>
<ol><li>制定计划（拆解自己的业务 SOP）</li></ol>
<ol><li>固定的执行动作通过代码完成</li></ol>
<ol><li>执行产生的结果，交给 AI，让AI 判断</li></ol>
<ol><li>根据 AI 的判断，选择下一步执行的动作（只做选择，不是让他自己规划）</li></ol>

<p>而我们就是基于这一套思维拆解和制定了新的方案：</p>
<p>首先，我们前文说了内容通过各种高消费榜单和各国本地网站而来，当我们抓取入库之后，运营会根据当天发生的事情来获取对应的信息流文章判断是否属于爆款，是否需要构建专题热榜等。</p>
<p>其次，如果需要构建爆款，那么运营会书写总结这个爆款的大话题是什么，子节点话题是什么，创建话题的标题和节点标题来构建爆款，做后续的运营动作，比如 push 推送、热榜置顶等；</p>
<p>所以这个过程中就涉及到识别是否是爆款、已有子爆款归属、编辑创建爆款名称，创建之后，就是正常的机器根据数据判断执行动作</p>

<h3>第二步：每一个单独的工作流，有规则的融合到一起</h3>

<p>在清楚了每一个动作之后，就开始对现有流程的改造，因为 gemini2.0 成本的大幅下降，已经可以放心的折腾了</p>
<ol><li>首先是识别爆款，同时给出爆款的名称，把文章内容和对应的提示词以及对应的其他属性给到 AI，返回结构化 json 数据，后续业务根据动作来做下一步事情</li></ol>

<p>在文章入库的时候，就判断是否是爆款事件，对于爆款事件的定义在每个国家不一样，所以在提示词中需要充分的加入背景信息以及背景文化，评判标准；</p>
<p>这其中我们遇到过一个坑，对于全球通用性爆款的判断一开始归属到了具体的国家里面，最后发现事件对于他国是不关注的。但是会错失这种爆款的发现，所以需要加入足够的信息</p>
<p>对于 AI 而言，我们发现只要标准给的足够细，让其同时给出理由的时候，就会更加准确，这个也是因为大模型的原理，感兴趣的可以再聊。</p>
<p>所以我们给出了不同的等级 S、A、B 、normal 等级别，S 我们定义为爆款爆款，A 定义为爆款，B 和 normal 都是普通等级；</p>
<p>这里单独抽象出来一个 B ，是因为在调试的过程中发现有些模糊的地带，对于大模型而言还是会判断的不太明确，所以就加了一个等级在爆款内容和普通内容之间，这样就归为 B，保证了 S/A 的归类的准确度比较高；</p>
<p>所以，明确你的需求、背景、想要的东西，细化，再细化，AI 就会给你想要的东西</p>
<ol><li>  其次，对于判断是 S、A 的文章内容，结合已经在线上运营且是有效期的爆款标题命名再通过 AI 判断，是否已经是属于有效期内爆款，如果已经是了，那么就不再创建爆款，返回对应归属的爆款内容，记录入库。</li></ol>

<ol><li>如果是已经命中了爆款话题，那么就把文章和对应这个爆款话题已经存在的子话题一起传给 AI（新的一套子话题归属提示词），让 AI 判定是否是新的子话题，如果是已经属于已经创建的子话题，那么就记录下来，如果已经创建的子话题，那么就让 AI 给出属于什么新的子话题</li></ol>
<p>流程如下：</p>

<p>这个业务流程大概是如此，这里再举一个例子：</p>
<p>比如现在一篇文章写马拉西亚电商的内容，给到 AI 判断是否是属于爆款内容（可以定义一个标准，比如有数据、有结果、有细节、有一些方法论，面向的人群是哪些读者人群），评判出是爆款了，并且给出大分类是出海这个标签</p>

<p>第二步，然后看一下爆款内容里面是否有出海的文章，如果有，就把出海的所有子话题（比如说海外自媒体、海外电商、海外中介等）和这一篇马拉西亚电商的内容，一起给 AI，让 AI 判断是否是已经有讲这个话题的文章。然后记录是否存在以及存在哪个话题的关系</p>

<p>第三步，这个时候上一步会命中电商这个标签，然后再把海外电商这个标签下所有的文章简介和这篇文章的内容一起给到 AI，看看是不是讲的同一个子话题，比如说 tiktok、独立站之类的。</p>
<p>这个时候，就可以根据所有上面的判断来运营动作了，比如这篇文章判断是一个写马来西亚、电商 tiktok 的爆款内容，那么就可以定向推送给做这个领域的人群，增加他们的消费。</p>

<p>整个这一套 AI 改造的流程下来之后，我们公司的运营动作，就完全可以通过 AI 来驱动了，并且结合数据的反馈来调整提示词和工作流的细节。而这儿的反馈也很重要，他给了我们一个可持续迭代的动作和方向。之前看到了纳瓦尔说的一句话：</p>
<p>重要的不是一万个小时，而是一万次迭代</p>
<p>在现实生活中，不需要一万次迭代，正如我们前面做审核经历过四五次迭代之后，就已经平替并且做的更好了，并且我们总结了方法论，在今年的运营改造中，再来做就很快了。</p>

<h1>如何把 AI 工作流和实际业务相结合</h1>
<ol><li>拆解，把工作的细节拆解的足够细致。拆解一个人的工作，也是输入和输出，但最终会形成动作的是输出。实际业务落到最终就是实际岗位，所以拆解业务，不如拆解某一个岗位的某一个工作的细节</li></ol>
<ul><li>初始信息+特定业务场景提示词 = AI 输入</li></ul>
<ul><li>AI 给出的参数 + 参数决定的固定可选的工作流=人的某一个业务动作的结果</li></ul>
<ul><li>业务动作的结果+其他输入 = AI 给出的参数</li></ul>
<ol><li>测试 MVP 的时候，先不计成本，业务链路能够跑通，再说压缩成本的事情</li></ol>
<ol><li>我们这两个业务场景的温度都设置的是 0，对于判定性的内容，识别性的内容，我们测试下来温度是 0 最优，创作性的大概在 0.3～0.5 之间</li></ol>
<ol><li>判定性、识别性的内容，要保障 Ai 的准确性，让它给出理由，这个也和大模型的底层原理有关</li></ol>
<ol><li>改造业务，不用想着改造一整块，或者一个岗位，一步到位的情况。要有迭代思维，就只做一个工作的细节，逐步推进，成功概率更高，成本更可控，再持续迭代</li></ol>
<ol><li>使用 AI，用发展的眼光来看待，如同我们一开始的 GPt3.5 -&gt; GPT4V  -&gt; GPT4o -&gt;  Gemini2.0一路走来，因为一开始的相信，才有了现在的结果。</li></ol>
<ol><li>详细阅读官方文档，识别能力边界和官方推荐的方向</li></ol>

<p>最后，我在这接近两年对公司业务的 AI 化改造的过程中，发现以后超级个体、超级团队一定是未来的趋势，更多的人应该是业务操盘手，看数据做决定、改造工作流、执行下一步动作。至于未来真正的模样，AI 所带来的大面积人员优化，何去何从，我也想不明白，看不清楚，这应该是一个人文问题。但是我相信一件事情，就从现在开始，和 AI 一起携手共进，未来就一定可以获得百倍收益，并且 AI 所带来的全社会的收益一定是可以把整个世界的电梯更上一层，就如同工业革命，但更胜于工业革命。</p>